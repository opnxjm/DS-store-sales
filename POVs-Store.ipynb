{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:58:56.577850Z",
     "iopub.status.busy": "2024-11-20T15:58:56.577415Z",
     "iopub.status.idle": "2024-11-20T15:59:01.390949Z",
     "shell.execute_reply": "2024-11-20T15:59:01.389744Z",
     "shell.execute_reply.started": "2024-11-20T15:58:56.577814Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:59:03.998571Z",
     "iopub.status.busy": "2024-11-20T15:59:03.998170Z",
     "iopub.status.idle": "2024-11-20T15:59:04.165482Z",
     "shell.execute_reply": "2024-11-20T15:59:04.164424Z",
     "shell.execute_reply.started": "2024-11-20T15:59:03.998534Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in the 'family' column:\n",
      "['AUTOMOTIVE' 'BABY CARE' 'BEAUTY' 'BEVERAGES' 'BOOKS' 'BREAD/BAKERY'\n",
      " 'CELEBRATION' 'CLEANING' 'DAIRY' 'DELI' 'EGGS' 'FROZEN FOODS' 'GROCERY I'\n",
      " 'GROCERY II' 'HARDWARE' 'HOME AND KITCHEN I' 'HOME AND KITCHEN II'\n",
      " 'HOME APPLIANCES' 'HOME CARE' 'LADIESWEAR' 'LAWN AND GARDEN' 'LINGERIE'\n",
      " 'LIQUOR,WINE,BEER' 'MAGAZINES' 'MEATS' 'PERSONAL CARE' 'PET SUPPLIES'\n",
      " 'PLAYERS AND ELECTRONICS' 'POULTRY' 'PREPARED FOODS' 'PRODUCE'\n",
      " 'SCHOOL AND OFFICE SUPPLIES' 'SEAFOOD']\n",
      "\n",
      "Number of unique families: 33\n"
     ]
    }
   ],
   "source": [
    "# Get unique values from the 'family' column\n",
    "unique_families = train['family'].unique()\n",
    "\n",
    "\n",
    "print(\"Unique values in the 'family' column:\")\n",
    "print(unique_families)\n",
    "\n",
    "\n",
    "num_unique_families = len(unique_families)\n",
    "print(f\"\\nNumber of unique families: {num_unique_families}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T15:59:10.133069Z",
     "iopub.status.busy": "2024-11-20T15:59:10.132661Z",
     "iopub.status.idle": "2024-11-20T15:59:17.747347Z",
     "shell.execute_reply": "2024-11-20T15:59:17.746327Z",
     "shell.execute_reply.started": "2024-11-20T15:59:10.133036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Family  Average Sales\n",
      "0                   AUTOMOTIVE       6.101236\n",
      "1                    BABY CARE       0.110528\n",
      "2                       BEAUTY       3.715723\n",
      "3                    BEVERAGES    2385.793151\n",
      "4                        BOOKS       0.070797\n",
      "5                 BREAD/BAKERY     463.336254\n",
      "6                  CELEBRATION       8.370469\n",
      "7                     CLEANING    1072.416744\n",
      "8                        DAIRY     709.154889\n",
      "9                         DELI     265.135067\n",
      "10                        EGGS     171.420516\n",
      "11                FROZEN FOODS     154.766954\n",
      "12                   GROCERY I    3776.972100\n",
      "13                  GROCERY II      21.584048\n",
      "14                    HARDWARE       1.137833\n",
      "15          HOME AND KITCHEN I      20.470342\n",
      "16         HOME AND KITCHEN II      16.722420\n",
      "17             HOME APPLIANCES       0.457476\n",
      "18                   HOME CARE     176.198029\n",
      "19                  LADIESWEAR       7.160629\n",
      "20             LAWN AND GARDEN       6.035475\n",
      "21                    LINGERIE       7.182128\n",
      "22            LIQUOR,WINE,BEER      85.187824\n",
      "23                   MAGAZINES       2.929082\n",
      "24                       MEATS     341.849965\n",
      "25               PERSONAL CARE     270.432513\n",
      "26                PET SUPPLIES       3.921263\n",
      "27     PLAYERS AND ELECTRONICS       6.186857\n",
      "28                     POULTRY     350.532292\n",
      "29              PREPARED FOODS      96.770202\n",
      "30                     PRODUCE    1349.352123\n",
      "31  SCHOOL AND OFFICE SUPPLIES       2.961599\n",
      "32                     SEAFOOD      22.163190\n"
     ]
    }
   ],
   "source": [
    "# List of unique families\n",
    "unique_families = [\n",
    "    'AUTOMOTIVE', 'BABY CARE', 'BEAUTY', 'BEVERAGES', 'BOOKS', 'BREAD/BAKERY',\n",
    "    'CELEBRATION', 'CLEANING', 'DAIRY', 'DELI', 'EGGS', 'FROZEN FOODS', 'GROCERY I',\n",
    "    'GROCERY II', 'HARDWARE', 'HOME AND KITCHEN I', 'HOME AND KITCHEN II',\n",
    "    'HOME APPLIANCES', 'HOME CARE', 'LADIESWEAR', 'LAWN AND GARDEN', 'LINGERIE',\n",
    "    'LIQUOR,WINE,BEER', 'MAGAZINES', 'MEATS', 'PERSONAL CARE', 'PET SUPPLIES',\n",
    "    'PLAYERS AND ELECTRONICS', 'POULTRY', 'PREPARED FOODS', 'PRODUCE',\n",
    "    'SCHOOL AND OFFICE SUPPLIES', 'SEAFOOD'\n",
    "]\n",
    "\n",
    "# Dictionary to store average sales for each family\n",
    "average_sales = {}\n",
    "\n",
    "\n",
    "for family in unique_families:\n",
    "    avg_sales = train.loc[train['family'] == family, 'sales'].mean()\n",
    "    average_sales[family] = avg_sales\n",
    "\n",
    "# Convert the dictionary to a DataFrame \n",
    "average_sales_df = pd.DataFrame(list(average_sales.items()), columns=['Family', 'Average Sales'])\n",
    "\n",
    "\n",
    "print(average_sales_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-21T14:54:28.197494Z",
     "iopub.status.busy": "2024-11-21T14:54:28.197025Z",
     "iopub.status.idle": "2024-11-21T14:54:37.197533Z",
     "shell.execute_reply": "2024-11-21T14:54:37.195370Z",
     "shell.execute_reply.started": "2024-11-21T14:54:28.197456Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error: 0.9516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train['is_1st_Jan'] = ((train['date'].dt.month == 1) & (train['date'].dt.day == 1)).astype(int)\n",
    "\n",
    "is_closed = {'store_nbr': [], 'closed_1st_Jan': [], 'open_date': []}\n",
    "\n",
    "for store in train['store_nbr'].unique():\n",
    "    closed_on_jan1 = (train['is_1st_Jan'] > 0) & (train['store_nbr'] == store)\n",
    "    is_closed['store_nbr'].append(store)\n",
    "    is_closed['closed_1st_Jan'].append(np.sum(train['sales'][closed_on_jan1]) < 0.1)\n",
    "    is_closed['open_date'].append(np.min(train['date'][closed_on_jan1]))\n",
    "\n",
    "is_closed_df = pd.DataFrame(is_closed)\n",
    "\n",
    "train = pd.merge(train, is_closed_df, on='store_nbr', how='left')\n",
    "train['is_closed'] = (train['date'] < train['open_date']) | (train['is_1st_Jan'] & train['closed_1st_Jan'])\n",
    "\n",
    "if 'is_sales' in train:\n",
    "    train.drop(['is_sales'], axis=1, inplace=True)\n",
    "    \n",
    "df_grouped = (train.groupby(['store_nbr', 'family'])\n",
    "              .rolling(window=30, on='date')['sales']\n",
    "              .sum()\n",
    "              .bfill()\n",
    "              .reset_index())\n",
    "\n",
    "df_grouped['is_sales'] = df_grouped['sales'] > 0\n",
    "df_grouped.drop(['sales'], axis=1, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df_grouped, how='left')\n",
    "train['is_sales'] = train['is_sales'] & (~train['is_closed'])\n",
    "\n",
    "books_sales_index = (train['family'] == 'BOOKS') & (train['sales'] > 0)\n",
    "date_books_start = np.min(train['date'][books_sales_index])\n",
    "average_books_sales = np.mean(train['sales'][books_sales_index])\n",
    "\n",
    "train['is_sales'] = np.where(train['family'] == 'BOOKS', 0, train['is_sales'])\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "def get_category_inflation(df_grouped, train_ind):\n",
    "    \"\"\"\n",
    "    Calculates category-specific inflation trends based on a linear regression model \n",
    "    applied to each unique 'family' category in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df_grouped : pd.DataFrame\n",
    "        DataFrame containing sales data. It must include the columns 'day_n', \n",
    "        'family', and 'sales'.\n",
    "    train_ind : np.ndarray or pd.Series\n",
    "        Boolean array or Series indicating the training data rows.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing columns 'day_n', 'family', and the calculated\n",
    "        'cat_inflation'.\n",
    "    \"\"\"\n",
    "    inflation_values = np.full(df_grouped.shape[0], np.mean(df_grouped['sales']))\n",
    "    \n",
    "    for family in df_grouped['family'].unique():\n",
    "        family_mask = (df_grouped['family'] == family)\n",
    "        train_mask = family_mask & train_ind\n",
    "        \n",
    "        if not np.any(train_mask):\n",
    "            continue\n",
    "        \n",
    "        lr.fit(df_grouped[['day_n']][train_mask], df_grouped['sales'][train_mask])\n",
    "        inflation_values[family_mask] = lr.predict(df_grouped[['day_n']][family_mask])\n",
    "\n",
    "    df_grouped['cat_inflation'] = inflation_values\n",
    "    return df_grouped[['day_n', 'family', 'cat_inflation']]\n",
    "\n",
    "train['day_n'] = (train['date'] - train['date'].min()).dt.days\n",
    "df_grouped = train[train['is_sales'] == 1].groupby(['day_n', 'family'])[['sales']].mean().reset_index()\n",
    "\n",
    "train_ind = df_grouped['day_n'] < 1350\n",
    "df_grouped = get_category_inflation(df_grouped, train_ind)\n",
    "\n",
    "train = pd.merge(train, df_grouped, on=['day_n', 'family'], how='left')\n",
    "train['pred'] = train['cat_inflation'].fillna(0)\n",
    "train['pred'] = np.where(train['is_sales'] == 0, 0, train['pred'])\n",
    "train['pred'] = np.maximum(train['pred'], 0)\n",
    "\n",
    "train_ind = train['day_n'] < 1350\n",
    "test_ind = ~train_ind\n",
    "rmsle = np.sqrt(mean_squared_log_error(train['sales'][test_ind], train['pred'][test_ind]))\n",
    "print(f\"Root Mean Squared Log Error: {rmsle:.4f}\")\n",
    "\n",
    "is_sales_test = train[['store_nbr', 'family', 'is_sales']][train['date'] == '2017-08-15']\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['day_n'] = (test['date'] - train['date'].min()).dt.days\n",
    "test = pd.merge(test, is_sales_test, how='left', on=['store_nbr', 'family'])\n",
    "\n",
    "df_avg_sales = train[train['is_sales'] == 1].groupby(['day_n', 'family'])[['sales']].mean().reset_index()\n",
    "df_test_sales = test[test['is_sales'] == 1][['day_n', 'family']].drop_duplicates()\n",
    "df_combined = pd.concat([df_avg_sales, df_test_sales])\n",
    "\n",
    "train_ind = df_combined['day_n'] < df_test_sales['day_n'].min()\n",
    "\n",
    "df_combined = get_category_inflation(df_combined, train_ind)\n",
    "\n",
    "test = pd.merge(test, df_combined, how='left')\n",
    "test['sales'] = np.where(test['is_sales'] == 0, 0, test['cat_inflation'])\n",
    "test['sales'] = test['sales'].fillna(0)\n",
    "\n",
    "submission = test[['id', 'sales']].drop_duplicates()\n",
    "submission.to_csv('submission_linear.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression without feature engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:56:05.955673Z",
     "iopub.status.busy": "2024-11-21T14:56:05.955252Z",
     "iopub.status.idle": "2024-11-21T14:56:12.724334Z",
     "shell.execute_reply": "2024-11-21T14:56:12.723241Z",
     "shell.execute_reply.started": "2024-11-21T14:56:05.955635Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Log Error: 0.9823\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "\n",
    "df_grouped = (train.groupby(['store_nbr', 'family'])\n",
    "              .rolling(window=30, on='date')['sales']\n",
    "              .sum()\n",
    "              .bfill()\n",
    "              .reset_index())\n",
    "\n",
    "df_grouped['is_sales'] = df_grouped['sales'] > 0\n",
    "df_grouped.drop(['sales'], axis=1, inplace=True)\n",
    "\n",
    "train = pd.merge(train, df_grouped, how='left')\n",
    "\n",
    "books_sales_index = (train['family'] == 'BOOKS') & (train['sales'] > 0)\n",
    "date_books_start = np.min(train['date'][books_sales_index])\n",
    "average_books_sales = np.mean(train['sales'][books_sales_index])\n",
    "\n",
    "train['is_sales'] = np.where(train['family'] == 'BOOKS', 0, train['is_sales'])\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "def get_category_inflation(df_grouped, train_ind):\n",
    "    \"\"\"\n",
    "    Calculates category-specific inflation trends based on a linear regression model \n",
    "    applied to each unique 'family' category in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    df_grouped : pd.DataFrame\n",
    "        DataFrame containing sales data. It must include the columns 'day_n', \n",
    "        'family', and 'sales'.\n",
    "    train_ind : np.ndarray or pd.Series\n",
    "        Boolean array or Series indicating the training data rows.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing columns 'day_n', 'family', and the calculated\n",
    "        'cat_inflation'.\n",
    "    \"\"\"\n",
    "    inflation_values = np.full(df_grouped.shape[0], np.mean(df_grouped['sales']))\n",
    "\n",
    "    for family in df_grouped['family'].unique():\n",
    "        family_mask = (df_grouped['family'] == family)\n",
    "        train_mask = family_mask & train_ind\n",
    "        \n",
    "        if not np.any(train_mask):\n",
    "            continue\n",
    "        \n",
    "        lr.fit(df_grouped[['day_n']][train_mask], df_grouped['sales'][train_mask])\n",
    "        inflation_values[family_mask] = lr.predict(df_grouped[['day_n']][family_mask])\n",
    "\n",
    "    df_grouped['cat_inflation'] = inflation_values\n",
    "    return df_grouped[['day_n', 'family', 'cat_inflation']]\n",
    "\n",
    "train['day_n'] = (train['date'] - train['date'].min()).dt.days\n",
    "df_grouped = train[train['is_sales'] == 1].groupby(['day_n', 'family'])[['sales']].mean().reset_index()\n",
    "\n",
    "train_ind = df_grouped['day_n'] < 1350\n",
    "df_grouped = get_category_inflation(df_grouped, train_ind)\n",
    "\n",
    "train = pd.merge(train, df_grouped, on=['day_n', 'family'], how='left')\n",
    "train['pred'] = train['cat_inflation'].fillna(0)\n",
    "train['pred'] = np.where(train['is_sales'] == 0, 0, train['pred'])\n",
    "train['pred'] = np.maximum(train['pred'], 0)\n",
    "\n",
    "train_ind = train['day_n'] < 1350\n",
    "test_ind = ~train_ind\n",
    "rmsle = np.sqrt(mean_squared_log_error(train['sales'][test_ind], train['pred'][test_ind]))\n",
    "print(f\"Root Mean Squared Log Error: {rmsle:.4f}\")\n",
    "\n",
    "is_sales_test = train[['store_nbr', 'family', 'is_sales']][train['date'] == '2017-08-15']\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "test['day_n'] = (test['date'] - train['date'].min()).dt.days\n",
    "test = pd.merge(test, is_sales_test, how='left', on=['store_nbr', 'family'])\n",
    "\n",
    "df_avg_sales = train[train['is_sales'] == 1].groupby(['day_n', 'family'])[['sales']].mean().reset_index()\n",
    "df_test_sales = test[test['is_sales'] == 1][['day_n', 'family']].drop_duplicates()\n",
    "df_combined = pd.concat([df_avg_sales, df_test_sales])\n",
    "train_ind = df_combined['day_n'] < df_test_sales['day_n'].min()\n",
    "\n",
    "df_combined = get_category_inflation(df_combined, train_ind)\n",
    "\n",
    "test = pd.merge(test, df_combined, how='left')\n",
    "test['sales'] = np.where(test['is_sales'] == 0, 0, test['cat_inflation'])\n",
    "test['sales'] = test['sales'].fillna(0)\n",
    "\n",
    "submission = test[['id', 'sales']].drop_duplicates()\n",
    "submission.to_csv('submission_without.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T16:02:19.642273Z",
     "iopub.status.busy": "2024-11-20T16:02:19.641858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Step 2: Load Data\n",
    "train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')\n",
    "stores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')\n",
    "oil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv')\n",
    "holidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv')\n",
    "\n",
    "# Step 3: Merge Datasets\n",
    "def merge_data(df):\n",
    "    df = df.merge(stores, on='store_nbr', how='left')\n",
    "    df = df.merge(oil, on='date', how='left')\n",
    "    df = df.merge(holidays, on='date', how='left')\n",
    "    return df\n",
    "\n",
    "train = merge_data(train)\n",
    "test = merge_data(test)\n",
    "\n",
    "# Step 4: Handle Missing Values\n",
    "def fill_missing_values(df):\n",
    "    df = df.copy()  # Avoid chained assignment issues\n",
    "    df['onpromotion'] = df['onpromotion'].fillna(0)\n",
    "    df['dcoilwtico'] = df['dcoilwtico'].ffill()\n",
    "    return df\n",
    "\n",
    "train = fill_missing_values(train)\n",
    "test = fill_missing_values(test)\n",
    "\n",
    "# Step 5: Feature Engineering\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)\n",
    "\n",
    "# Step 6: Aggregate Sales Data\n",
    "train_grouped = train.groupby(\n",
    "    ['store_nbr', 'family', 'year', 'month', 'day', 'day_of_week', 'onpromotion', 'dcoilwtico'], \n",
    "    as_index=False\n",
    ")['sales'].sum()\n",
    "\n",
    "# Step 7: Encoding Categorical Features\n",
    "train_encoded = pd.get_dummies(train_grouped, columns=['family'], drop_first=True)\n",
    "\n",
    "X = train_encoded.drop('sales', axis=1)\n",
    "y = train_encoded['sales']\n",
    "\n",
    "# Step 8: K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "rmsle_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Step 9: Train the Model\n",
    "    model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Step 10: Evaluate Model Performance\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_val, np.maximum(0, y_pred)))  # Avoid negative predictions\n",
    "    rmsle_scores.append(rmsle)\n",
    "\n",
    "print(f'Average RMSLE (K-Fold CV): {np.mean(rmsle_scores):.4f}')\n",
    "\n",
    "# Step 11: Prepare Test Data for Prediction\n",
    "test_encoded = pd.get_dummies(test, columns=['family'], drop_first=True)\n",
    "\n",
    "X_test = test_encoded.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "if 'id' in X_test.columns:\n",
    "    X_test = X_test.drop('id', axis=1)\n",
    "\n",
    "# Step 12: Train the Model on the Entire Training Set for Final Predictions\n",
    "model.fit(X, y)  # Fit model on the entire training data\n",
    "\n",
    "# Step 13: Predict on Test Set\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "# Step 14: Create Submission File\n",
    "submission = pd.DataFrame({\n",
    "    'id': test['id'],\n",
    "    'sales': np.maximum(0, test_preds)  # Ensure non-negative predictions\n",
    "})\n",
    "submission.to_csv('submission_3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration and Preparation in Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:16:36.886942Z",
     "iopub.status.busy": "2024-11-21T14:16:36.886502Z",
     "iopub.status.idle": "2024-11-21T14:16:38.999931Z",
     "shell.execute_reply": "2024-11-21T14:16:38.998751Z",
     "shell.execute_reply.started": "2024-11-21T14:16:36.886903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# Step 2: Load Data\n",
    "train = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/test.csv')\n",
    "stores = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/stores.csv')\n",
    "oil = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/oil.csv')\n",
    "holidays = pd.read_csv('/kaggle/input/store-sales-time-series-forecasting/holidays_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:16:46.643230Z",
     "iopub.status.busy": "2024-11-21T14:16:46.642809Z",
     "iopub.status.idle": "2024-11-21T14:16:50.565995Z",
     "shell.execute_reply": "2024-11-21T14:16:50.564701Z",
     "shell.execute_reply.started": "2024-11-21T14:16:46.643194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Train Dataset Structure:\n",
      "   id        date  store_nbr      family  sales  onpromotion   city  \\\n",
      "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0  Quito   \n",
      "1   1  2013-01-01          1   BABY CARE    0.0            0  Quito   \n",
      "2   2  2013-01-01          1      BEAUTY    0.0            0  Quito   \n",
      "3   3  2013-01-01          1   BEVERAGES    0.0            0  Quito   \n",
      "4   4  2013-01-01          1       BOOKS    0.0            0  Quito   \n",
      "\n",
      "       state type_x  cluster  dcoilwtico   type_y    locale locale_name  \\\n",
      "0  Pichincha      D       13         NaN  Holiday  National     Ecuador   \n",
      "1  Pichincha      D       13         NaN  Holiday  National     Ecuador   \n",
      "2  Pichincha      D       13         NaN  Holiday  National     Ecuador   \n",
      "3  Pichincha      D       13         NaN  Holiday  National     Ecuador   \n",
      "4  Pichincha      D       13         NaN  Holiday  National     Ecuador   \n",
      "\n",
      "          description transferred  \n",
      "0  Primer dia del ano       False  \n",
      "1  Primer dia del ano       False  \n",
      "2  Primer dia del ano       False  \n",
      "3  Primer dia del ano       False  \n",
      "4  Primer dia del ano       False   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def merge_data(df):\n",
    "    df = df.merge(stores, on='store_nbr', how='left')\n",
    "    df = df.merge(oil, on='date', how='left')\n",
    "    df = df.merge(holidays, on='date', how='left')\n",
    "    return df\n",
    "\n",
    "train = merge_data(train)\n",
    "test = merge_data(test)\n",
    "\n",
    "print(\"Merged Train Dataset Structure:\")\n",
    "print(train.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:39:34.285147Z",
     "iopub.status.busy": "2024-11-21T14:39:34.284636Z",
     "iopub.status.idle": "2024-11-21T14:39:34.600750Z",
     "shell.execute_reply": "2024-11-21T14:39:34.599482Z",
     "shell.execute_reply.started": "2024-11-21T14:39:34.285099Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fill_missing_values(df):\n",
    "    df = df.copy()\n",
    "    df['onpromotion'] = df['onpromotion'].fillna(0)\n",
    "    df['dcoilwtico'] = df['dcoilwtico'].ffill()\n",
    "    return df\n",
    "\n",
    "train = fill_missing_values(train)\n",
    "test = fill_missing_values(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:39:56.348119Z",
     "iopub.status.busy": "2024-11-21T14:39:56.347723Z",
     "iopub.status.idle": "2024-11-21T14:39:57.038752Z",
     "shell.execute_reply": "2024-11-21T14:39:57.037613Z",
     "shell.execute_reply.started": "2024-11-21T14:39:56.348088Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    return df\n",
    "\n",
    "train = create_features(train)\n",
    "test = create_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:35:10.276218Z",
     "iopub.status.busy": "2024-11-21T14:35:10.275807Z",
     "iopub.status.idle": "2024-11-21T14:35:12.770833Z",
     "shell.execute_reply": "2024-11-21T14:35:12.769841Z",
     "shell.execute_reply.started": "2024-11-21T14:35:10.276186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_grouped = train.groupby(\n",
    "    ['store_nbr', 'family', 'year', 'month', 'day', 'day_of_week', 'onpromotion', 'dcoilwtico'], \n",
    "    as_index=False\n",
    ")['sales'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T14:19:31.049340Z",
     "iopub.status.busy": "2024-11-21T14:19:31.048914Z",
     "iopub.status.idle": "2024-11-21T14:19:31.413963Z",
     "shell.execute_reply": "2024-11-21T14:19:31.412861Z",
     "shell.execute_reply.started": "2024-11-21T14:19:31.049302Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Train Dataset Structure:\n",
      "   store_nbr  year  month  day  day_of_week  onpromotion  dcoilwtico  sales  \\\n",
      "0          1  2013      1    2            2            0       93.14    2.0   \n",
      "1          1  2013      1    3            3            0       92.97    3.0   \n",
      "2          1  2013      1    4            4            0       93.12    3.0   \n",
      "3          1  2013      1    5            5            0       93.12    5.0   \n",
      "4          1  2013      1    6            6            0       93.12    2.0   \n",
      "\n",
      "   family_BABY CARE  family_BEAUTY  ...  family_MAGAZINES  family_MEATS  \\\n",
      "0             False          False  ...             False         False   \n",
      "1             False          False  ...             False         False   \n",
      "2             False          False  ...             False         False   \n",
      "3             False          False  ...             False         False   \n",
      "4             False          False  ...             False         False   \n",
      "\n",
      "   family_PERSONAL CARE  family_PET SUPPLIES  family_PLAYERS AND ELECTRONICS  \\\n",
      "0                 False                False                           False   \n",
      "1                 False                False                           False   \n",
      "2                 False                False                           False   \n",
      "3                 False                False                           False   \n",
      "4                 False                False                           False   \n",
      "\n",
      "   family_POULTRY  family_PREPARED FOODS  family_PRODUCE  \\\n",
      "0           False                  False           False   \n",
      "1           False                  False           False   \n",
      "2           False                  False           False   \n",
      "3           False                  False           False   \n",
      "4           False                  False           False   \n",
      "\n",
      "   family_SCHOOL AND OFFICE SUPPLIES  family_SEAFOOD  \n",
      "0                              False           False  \n",
      "1                              False           False  \n",
      "2                              False           False  \n",
      "3                              False           False  \n",
      "4                              False           False  \n",
      "\n",
      "[5 rows x 40 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_encoded = pd.get_dummies(train_grouped, columns=['family'], drop_first=True)\n",
    "\n",
    "# Print encoded train structure\n",
    "print(\"Encoded Train Dataset Structure:\")\n",
    "print(train_encoded.head(), \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2887556,
     "sourceId": 29781,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
